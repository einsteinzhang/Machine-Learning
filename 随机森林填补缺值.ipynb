{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 导入需要的库\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.impute import SimpleImputer#填补空值\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 以波士顿数据集为例，导入完整的数据集并探索\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(506, 13)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "dataset.data.shape\n",
    "#总共506*13=6578个数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 标签是连续性变量！！！！！所以标签是连续变量---要做的就是回归！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([24. , 21.6, 34.7, 33.4, 36.2, 28.7, 22.9, 27.1, 16.5, 18.9, 15. ,\n",
       "       18.9, 21.7, 20.4, 18.2, 19.9, 23.1, 17.5, 20.2, 18.2, 13.6, 19.6,\n",
       "       15.2, 14.5, 15.6, 13.9, 16.6, 14.8, 18.4, 21. , 12.7, 14.5, 13.2,\n",
       "       13.1, 13.5, 18.9, 20. , 21. , 24.7, 30.8, 34.9, 26.6, 25.3, 24.7,\n",
       "       21.2, 19.3, 20. , 16.6, 14.4, 19.4, 19.7, 20.5, 25. , 23.4, 18.9,\n",
       "       35.4, 24.7, 31.6, 23.3, 19.6, 18.7, 16. , 22.2, 25. , 33. , 23.5,\n",
       "       19.4, 22. , 17.4, 20.9, 24.2, 21.7, 22.8, 23.4, 24.1, 21.4, 20. ,\n",
       "       20.8, 21.2, 20.3, 28. , 23.9, 24.8, 22.9, 23.9, 26.6, 22.5, 22.2,\n",
       "       23.6, 28.7, 22.6, 22. , 22.9, 25. , 20.6, 28.4, 21.4, 38.7, 43.8,\n",
       "       33.2, 27.5, 26.5, 18.6, 19.3, 20.1, 19.5, 19.5, 20.4, 19.8, 19.4,\n",
       "       21.7, 22.8, 18.8, 18.7, 18.5, 18.3, 21.2, 19.2, 20.4, 19.3, 22. ,\n",
       "       20.3, 20.5, 17.3, 18.8, 21.4, 15.7, 16.2, 18. , 14.3, 19.2, 19.6,\n",
       "       23. , 18.4, 15.6, 18.1, 17.4, 17.1, 13.3, 17.8, 14. , 14.4, 13.4,\n",
       "       15.6, 11.8, 13.8, 15.6, 14.6, 17.8, 15.4, 21.5, 19.6, 15.3, 19.4,\n",
       "       17. , 15.6, 13.1, 41.3, 24.3, 23.3, 27. , 50. , 50. , 50. , 22.7,\n",
       "       25. , 50. , 23.8, 23.8, 22.3, 17.4, 19.1, 23.1, 23.6, 22.6, 29.4,\n",
       "       23.2, 24.6, 29.9, 37.2, 39.8, 36.2, 37.9, 32.5, 26.4, 29.6, 50. ,\n",
       "       32. , 29.8, 34.9, 37. , 30.5, 36.4, 31.1, 29.1, 50. , 33.3, 30.3,\n",
       "       34.6, 34.9, 32.9, 24.1, 42.3, 48.5, 50. , 22.6, 24.4, 22.5, 24.4,\n",
       "       20. , 21.7, 19.3, 22.4, 28.1, 23.7, 25. , 23.3, 28.7, 21.5, 23. ,\n",
       "       26.7, 21.7, 27.5, 30.1, 44.8, 50. , 37.6, 31.6, 46.7, 31.5, 24.3,\n",
       "       31.7, 41.7, 48.3, 29. , 24. , 25.1, 31.5, 23.7, 23.3, 22. , 20.1,\n",
       "       22.2, 23.7, 17.6, 18.5, 24.3, 20.5, 24.5, 26.2, 24.4, 24.8, 29.6,\n",
       "       42.8, 21.9, 20.9, 44. , 50. , 36. , 30.1, 33.8, 43.1, 48.8, 31. ,\n",
       "       36.5, 22.8, 30.7, 50. , 43.5, 20.7, 21.1, 25.2, 24.4, 35.2, 32.4,\n",
       "       32. , 33.2, 33.1, 29.1, 35.1, 45.4, 35.4, 46. , 50. , 32.2, 22. ,\n",
       "       20.1, 23.2, 22.3, 24.8, 28.5, 37.3, 27.9, 23.9, 21.7, 28.6, 27.1,\n",
       "       20.3, 22.5, 29. , 24.8, 22. , 26.4, 33.1, 36.1, 28.4, 33.4, 28.2,\n",
       "       22.8, 20.3, 16.1, 22.1, 19.4, 21.6, 23.8, 16.2, 17.8, 19.8, 23.1,\n",
       "       21. , 23.8, 23.1, 20.4, 18.5, 25. , 24.6, 23. , 22.2, 19.3, 22.6,\n",
       "       19.8, 17.1, 19.4, 22.2, 20.7, 21.1, 19.5, 18.5, 20.6, 19. , 18.7,\n",
       "       32.7, 16.5, 23.9, 31.2, 17.5, 17.2, 23.1, 24.5, 26.6, 22.9, 24.1,\n",
       "       18.6, 30.1, 18.2, 20.6, 17.8, 21.7, 22.7, 22.6, 25. , 19.9, 20.8,\n",
       "       16.8, 21.9, 27.5, 21.9, 23.1, 50. , 50. , 50. , 50. , 50. , 13.8,\n",
       "       13.8, 15. , 13.9, 13.3, 13.1, 10.2, 10.4, 10.9, 11.3, 12.3,  8.8,\n",
       "        7.2, 10.5,  7.4, 10.2, 11.5, 15.1, 23.2,  9.7, 13.8, 12.7, 13.1,\n",
       "       12.5,  8.5,  5. ,  6.3,  5.6,  7.2, 12.1,  8.3,  8.5,  5. , 11.9,\n",
       "       27.9, 17.2, 27.5, 15. , 17.2, 17.9, 16.3,  7. ,  7.2,  7.5, 10.4,\n",
       "        8.8,  8.4, 16.7, 14.2, 20.8, 13.4, 11.7,  8.3, 10.2, 10.9, 11. ,\n",
       "        9.5, 14.5, 14.1, 16.1, 14.3, 11.7, 13.4,  9.6,  8.7,  8.4, 12.8,\n",
       "       10.5, 17.1, 18.4, 15.4, 10.8, 11.8, 14.9, 12.6, 14.1, 13. , 13.4,\n",
       "       15.2, 16.1, 17.8, 14.9, 14.1, 12.7, 13.5, 14.9, 20. , 16.4, 17.7,\n",
       "       19.5, 20.2, 21.4, 19.9, 19. , 19.1, 19.1, 20.1, 19.9, 19.6, 23.2,\n",
       "       29.8, 13.8, 13.3, 16.7, 12. , 14.6, 21.4, 23. , 23.7, 25. , 21.8,\n",
       "       20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1, 13.6, 20.1, 21.8, 24.5,\n",
       "       23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4, 20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.target#标签是连续性变量！！！！！所以标签是连续变量---要做的就是回归！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_full, y_full = dataset.data, dataset.target\n",
    "n_samples = X_full.shape[0]\n",
    "n_features = X_full.shape[1]\n",
    "n_samples#样本的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features#标签的数量\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 为完整数据集放入缺失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3289"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#首先确定我们希望放入的缺失数据的比例，在这里我们假设是50%，那总共就要有3289个数据缺失\n",
    " \n",
    "rng = np.random.RandomState(0)\n",
    "missing_rate = 0.5\n",
    "n_missing_samples = int(np.floor(n_samples * n_features * missing_rate))\n",
    "#np.floor：向下取整，返回.0格式的浮点数\n",
    "n_missing_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0    1     2    3      4      5     6       7    8      9    10  \\\n",
       "0      NaN  NaN   NaN  NaN  0.538  6.575   NaN     NaN  1.0  296.0   NaN   \n",
       "1      NaN  0.0  7.07  0.0    NaN  6.421   NaN  4.9671  2.0    NaN  17.8   \n",
       "2  0.02729  0.0  7.07  0.0  0.469    NaN   NaN     NaN  2.0  242.0   NaN   \n",
       "3  0.03237  NaN   NaN  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4      NaN  0.0  2.18  0.0    NaN  7.147  54.2     NaN  NaN  222.0  18.7   \n",
       "\n",
       "       11    12  \n",
       "0  396.90  4.98  \n",
       "1  396.90   NaN  \n",
       "2     NaN  4.03  \n",
       "3  394.63   NaN  \n",
       "4  396.90  5.33  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#所有数据要随机遍布在数据集的各行各列当中，而一个缺失的数据会需要一个行索引和一个列索引\n",
    "#如果能够创造一个数组，包含3289个分布在0~506中间的行索引，和3289个分布在0~13之间的列索引，那我们就可\n",
    "#以利用索引来为数据中的任意3289个位置赋空值\n",
    "#然后我们用0，均值和随机森林来填写这些缺失值，然后查看回归的结果如何\n",
    " \n",
    "missing_features = rng.randint(0,n_features,n_missing_samples)\n",
    "#randint(下限，上限，n):上下限之间取出n个整数。\n",
    "missing_samples = rng.randint(0,n_samples,n_missing_samples)\n",
    "\n",
    "\n",
    "X_missing = X_full.copy()\n",
    "y_missing = y_full.copy()\n",
    " \n",
    "X_missing[missing_samples,missing_features] = np.nan\n",
    " \n",
    "X_missing = pd.DataFrame(X_missing)\n",
    "#转换成DataFrame是为了后续方便各种操作，numpy对矩阵的运算速度快到拯救人生，但是在索引等功能上却不如\n",
    "#pandas来得好用\n",
    "X_missing.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### y_missing 是标签，标签是不可以丢失的!所以不操作了！"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. 使用0和均值填补缺失值\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用均值进行填补\n",
    "from sklearn.impute import SimpleImputer\n",
    "imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_missing_mean = imp_mean.fit_transform(X_missing)\n",
    "\n",
    "#使用0进行填补\n",
    "imp_0 = SimpleImputer(missing_values=np.nan, strategy=\"constant\",fill_value=0)\n",
    "X_missing_0 = imp_0.fit_transform(X_missing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 检查是否都填补完毕："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_missing_mean).isnull().sum()#只要返回0，代表无空缺。pd.DataFrame：\n",
    "#为了只作为表格形式！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_missing_0).isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. **********************使用随机森林回归填补！！********************"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.421</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>273.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>393.45</td>\n",
       "      <td>6.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0    1      2    3      4      5     6       7    8      9    10  \\\n",
       "0        NaN  NaN    NaN  NaN  0.538  6.575   NaN     NaN  1.0  296.0   NaN   \n",
       "1        NaN  0.0   7.07  0.0    NaN  6.421   NaN  4.9671  2.0    NaN  17.8   \n",
       "2    0.02729  0.0   7.07  0.0  0.469    NaN   NaN     NaN  2.0  242.0   NaN   \n",
       "3    0.03237  NaN    NaN  0.0  0.458  6.998  45.8  6.0622  3.0  222.0  18.7   \n",
       "4        NaN  0.0   2.18  0.0    NaN  7.147  54.2     NaN  NaN  222.0  18.7   \n",
       "..       ...  ...    ...  ...    ...    ...   ...     ...  ...    ...   ...   \n",
       "501      NaN  0.0    NaN  0.0  0.573    NaN   NaN     NaN  1.0    NaN  21.0   \n",
       "502  0.04527  0.0  11.93  NaN    NaN  6.120  76.7  2.2875  NaN  273.0  21.0   \n",
       "503  0.06076  0.0    NaN  0.0  0.573    NaN  91.0     NaN  NaN  273.0  21.0   \n",
       "504  0.10959  0.0    NaN  NaN  0.573  6.794  89.3  2.3889  1.0  273.0   NaN   \n",
       "505  0.04741  0.0  11.93  0.0    NaN    NaN  80.8  2.5050  1.0    NaN  21.0   \n",
       "\n",
       "         11    12  \n",
       "0    396.90  4.98  \n",
       "1    396.90   NaN  \n",
       "2       NaN  4.03  \n",
       "3    394.63   NaN  \n",
       "4    396.90  5.33  \n",
       "..      ...   ...  \n",
       "501  391.99   NaN  \n",
       "502     NaN  9.08  \n",
       "503     NaN  5.64  \n",
       "504  393.45  6.48  \n",
       "505     NaN   NaN  \n",
       "\n",
       "[506 rows x 13 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_missing_reg = X_missing.copy()#先命名。\n",
    "X_missing_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  7,  8,  6,  0,  5, 11,  4,  9, 10, 12,  3,  1], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sortindex = np.argsort(X_missing_reg.isnull().sum(axis=0)).values\n",
    "#找出数据集中，缺失值从小到大排列的特征们的顺序。（本质是找索引）\n",
    "'''X_missing_reg.isnull():是否是空缺？转换成TorF\n",
    ".sum(axis=0)：按列求和；\n",
    " np.argsort：有索引的排列,注意这里是排列的索引！（np.sort：这样不会有索引!）\n",
    " .values：将排列的索引中的值提取！'''\n",
    "sortindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in sortindex:\n",
    "    \n",
    "    #构建我们的新特征矩阵（没有被选中去填充的特征+原始的标签）和新标签（选中去填充的特征）\n",
    "    df = X_missing_reg#避免一次操作就全部填0，无空缺。\n",
    "    fillc = df.iloc[:,i]\n",
    "    '''没有被选中去填充的特征df.iloc[:,df.columns != i]+原始的标签pd.DataFrame(y_full)\n",
    "     pd.concat(axis=1):将这两个矩阵左右连接，axis=0：上下连接'''\n",
    "    df = pd.concat([df.iloc[:,df.columns != i],pd.DataFrame(y_full)],axis=1)\n",
    "    \n",
    "    #在新特征矩阵中，对含有缺失值的列，进行0的填补\n",
    "    df_0 =SimpleImputer(missing_values=np.nan,\n",
    "                        strategy='constant',fill_value=0).fit_transform(df)\n",
    "    \n",
    "    #找出我们的训练集和测试集\n",
    "    Ytrain = fillc[fillc.notnull()]#被选中的要去填充的特征值（现在是标签）中非空值\n",
    "    Ytest = fillc[fillc.isnull()]#被选中的要去填充的特征值（现在是标签）中空值\n",
    "    #以上的Y的作用就是找到索引，方便下面的X使用。\n",
    "    Xtrain = df_0[Ytrain.index,:]#在新特征矩阵上，被选出要填充的特征的非空值所对应的行的其他列！\n",
    "    Xtest = df_0[Ytest.index,:]#在新特征矩阵上，被选出要填充的特征的空值所对应的行的其他列！\n",
    "    \n",
    "    #用随机森林回归来填补缺失\n",
    "    rfc = RandomForestRegressor(n_estimators=100)\n",
    "    rfc = rfc.fit(Xtrain, Ytrain)#导入训练集去训练\n",
    "    Ypredict = rfc.predict(Xtest)\n",
    "    #用predict接口将Xtest导入，得到我们的预测结果（回归结果），就是我们要用来填补空值的这些值\n",
    "    \n",
    "    \n",
    "    \n",
    "    #将填补好的特征返回到我们的原始的特征矩阵中\n",
    "    X_missing_reg.loc[X_missing_reg.iloc[:,i].isnull(),i] = Ypredict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0\n",
       "5     0\n",
       "6     0\n",
       "7     0\n",
       "8     0\n",
       "9     0\n",
       "10    0\n",
       "11    0\n",
       "12    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #检查是否有缺失值！！！\n",
    "    X_missing_reg.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. 对填补好的数据进行建模\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "X = [X_full,X_missing_mean,X_missing_0,X_missing_reg]\n",
    " \n",
    "mse = []\n",
    "std = []\n",
    "for x in X:\n",
    "    estimator = RandomForestRegressor(random_state=0, n_estimators=100)#实例化\n",
    "    scores = cross_val_score(estimator,x,y_full,scoring='neg_mean_squared_error', \n",
    "cv=5).mean()\n",
    "    mse.append(scores * -1)\n",
    "    #因为scoring='neg_mean_squared_error'得到的是负均方误差，所以变成正值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('x_full', 21.571667100368845),\n",
       " ('x_missing_mean', 52.568056917394664),\n",
       " ('x_missing_0', 44.611395707183064),\n",
       " ('x_missing_reg', 17.397535889303047)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#查案mse,越小越好！\n",
    "[*zip([\"x_full\",\"x_missing_mean\",\"x_missing_0\",\"x_missing_reg\"],mse)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[21.571667100368845,\n",
       " 52.568056917394664,\n",
       " 44.611395707183064,\n",
       " 17.397535889303047]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. 用所得结果画出条形图\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_labels = ['Full data',\n",
    "            'Zero Imputation',\n",
    "            'Mean Imputation',\n",
    "            'Regressor Imputation']\n",
    "colors = ['r', 'g', 'b', 'orange']\n",
    " \n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = plt.subplot(111)#添加子图。\n",
    "for i in np.arange(len(mse)):\n",
    "    ax.barh(i, mse[i],color=colors[i], alpha=0.6, align='center')\n",
    "    #barh：画条形图横过来的。 alpha=0.6:条的粗细\n",
    "ax.set_title('Imputation Techniques with Boston Data')\n",
    "ax.set_xlim(left=np.min(mse) * 0.9,\n",
    "             right=np.max(mse) * 1.1)#设置mse（x坐标）的范围。\n",
    "ax.set_yticks(np.arange(len(mse)))\n",
    "ax.set_xlabel('MSE')\n",
    "ax.set_yticklabels(x_labels)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
